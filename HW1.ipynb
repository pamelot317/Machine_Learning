{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA 208: Homework 1\n",
    "This is based on the material in Chapters 2, 3 of 'Elements of Statistical Learning' (ESL), in addition to lectures 1-4.  Chunzhe Zhang came up with the dataset and the analysis in the second section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "We use a script that extracts your answers by looking for cells in between the cells containing the exercise statements (beginning with __Exercise X.X__).  So you \n",
    "\n",
    "- MUST add cells in between the exercise statements and add answers within them and\n",
    "- MUST NOT modify the existing cells, particularly not the problem statement\n",
    "\n",
    "To make markdown, please switch the cell type to markdown (from code) - you can hit 'm' when you are in command mode - and use the markdown language.  For a brief tutorial see: https://daringfireball.net/projects/markdown/syntax\n",
    "\n",
    "In the conceptual exercises you should provide an explanation, with math when necessary, for any answers.  When answering with math you should use basic LaTeX, as in \n",
    "$$E(Y|X=x) = \\int_{\\mathcal{Y}} f_{Y|X}(y|x) dy = \\int_{\\mathcal{Y}} \\frac{f_{Y,X}(y,x)}{f_{X}(x)} dy$$\n",
    "for displayed equations, and $R_{i,j} = 2^{-|i-j|}$ for inline equations.  (To see the contents of this cell in markdown, double click on it or hit Enter in escape mode.)  To see a list of latex math symbols see here: http://web.ift.uib.no/Teori/KURS/WRK/TeX/symALL.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Conceptual Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1.1.__ (5 pts) Recall that the Hamming loss for Binary classification ($y \\in \\{0,1\\}$) is \n",
    "$$l(y,\\hat y) = 1\\{y \\ne \\hat y\\} = (y - \\hat y)^2$$\n",
    "as long as $\\hat y \\in \\{0,1\\}$.\n",
    "This loss can be extended to multiclass classification where there are $K$ possible values that $y$ can take (for example 'dog','cat','squirrel' or 1-5 stars).  Explain how you can re-encode $y$ and $\\hat y$ to be a $K-1$ dimensional vector that generalizes binary classification, and rewrite the loss using vector operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__:\n",
    "Let $y = (v_1,...,v_{k})^T$, where $v_i = \\{1$ if y = value i; 0 else $\\}$, for $i = 1,...,k$.  \n",
    "Thus, $$l(y,\\hat y) = (v_1 - \\hat v_1,...,v_{k} - \\hat v_{k})(v_1 - \\hat v_1,...,v_{k} - \\hat v_{k})^T$$  \n",
    "This gives the desired generalization and loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1.2__ (5 pts) Ex. 2.7 in ESL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__:  \n",
    "__(a)__ In linear regression, $\\hat f(X_0) = X_0\\hat\\beta = X_0(X^TX)^{-1}X^TY$  \n",
    "Since $X_0(X^TX)^{-1}X^T$ doesn't depend on y, we have $l(X_0;X)=X_0(X^TX)^{-1}X^T$.  So after matrix multiplication, we can see that $\\hat f(X_0)$ is of the desired form.  \n",
    "In kNN regression, $\\hat f(X_0) = \\frac{1}{k} \\sum_{i=1}^k y_i$, which is the average of the k-nearest neighbors of $X_0$.  So we can rewrite as $\\sum_{i=1}^N \\frac{1}{k}I_{\\{x_i \\in N(x_0)\\}}y_i$, where $N(X_0)$ is the neighborhood of k-nearest neighbors of $X_0$, and the $y_i$ corresponds to the $x_i$. So $l(X_0;X)=\\frac{1}{k}I_{\\{x_i \\in N(x_0)\\}}$ and $\\hat f(X_0)$ is of the desired form.  \n",
    "__(b)__ Note that $X, X_0,$ and $f(X_0)$ are fixed.  \n",
    "$E_{Y|X}((f(X_0) - \\hat f(X_0))^2) = E_{Y|X}(f(X_0)^2-2f(X_0)\\hat f(X_0) + \\hat f(X_0)^2)$  \n",
    "$= f(X_0)^2 - 2f(X_0)E_{Y|X}(\\hat f(X_0)) + E_{Y|X}(\\hat f(X_0))^2 - E_{Y|X}(\\hat f(X_0))^2 + E_{Y|X}(\\hat f(X_0)^2)$  \n",
    "$= (f(X_0) - E_{Y|X}(\\hat f(X_0)))^2 + E_{Y|X}(\\hat f(X_0)^2) - (E_{Y|X}(\\hat f(X_0)))^2$  \n",
    "$= bias^2 + Var(\\hat f(X_0)$  \n",
    "__(c)__ We will use the identity E(X) = E(E(X|Y)) in this part. Note here that only $X_0,$ and $f(X_0)$ are fixed.    \n",
    "$E_{Y,X}((f(X_0) - \\hat f(X_0))^2) = E_{Y,X}(E_{Y|X}((f(X_0) - \\hat f(X_0))^2))$  \n",
    "$= E_{Y,X}((f(X_0) - E_{Y|X}(\\hat f(X_0)))^2 + E_{Y|X}(\\hat f(X_0)^2) - (E_{Y|X}(\\hat f(X_0)))^2)$  \n",
    "$= (f(X_0) - E_{Y,X}(\\hat f(X_0))^2 - E_{Y,X}(\\hat f(X_0)^2) - (E_{Y,X}(\\hat f(X_0)))^2$  \n",
    "$= bias^2 + Var(\\hat f(X_0)$  \n",
    "__(d)__ As we saw in (c), the unconditional mean squared error is the expected value of the conditional mean squared error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1.3__ (5 pts, 1 for each part) Recall that the true risk for a prediction function, $f$, a loss function, $\\ell$, and a joint distribution for $Y,X$ is \n",
    "$$R(f) = E \\ell(y,f(x))$$\n",
    "For a training set $\\{x_i,y_x\\}_{i=1}^n$, the empirical risk is \n",
    "$$R_n = \\frac{1}{n} \\sum_{i=1}^n \\ell(y_i,f(x_i)).$$\n",
    "Let $y = x^\\top \\beta + \\epsilon$ be a linear model for $Y|X$, where $x,\\beta$ are $p$-dimensional such that $\\epsilon$ is Gaussian with mean 0 and variance $\\sigma^2$ (independent of X).\n",
    "Let $\\ell(y,\\hat y) = (y - \\hat y)^2$ be square error loss.\n",
    "\n",
    "1. Show that $f^\\star(x) = x^\\top \\beta$ gives the smallest true risk (also known as the Bayes rule).\n",
    "1. Why can't we use this prediction in practice?\n",
    "1. Recall that OLS is the empirical risk minimizer for linear functions.  Why does this tell us the following:\n",
    "$$ E R_n (\\hat f) \\le R(f^\\star)$$\n",
    "1. How do we know that $E R_n (\\hat f) \\le R(\\hat f)$? and use this to answer Ex. 2.9 in ESL.  \n",
    "1. What about this was specific to OLS and least squares loss (can this be generalized)?  What is the most general statement that you can think of that you can prove in this way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution:__  \n",
    "__(1)__ $R(f^\\star)=E(\\ell(y, f^\\star(x))) = E((X^T\\beta + \\epsilon - X^T\\beta)^2) = E(0) = 0$, which is clearly the smallest risk possible.  \n",
    "__(2)__ We can't use this prediction because we don't know $\\beta$.  \n",
    "__(3)__ First, $R_n(\\hat f) = \\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat f(x_i))^2 = \\frac{1}{n}\\sum_{i=1}^n(y_i-(x_{i1}\\hat\\beta_1+...+x_{ip}\\hat\\beta_p))^2$, where each $\\hat\\beta_i$ was chosen to minimize this sum. Now, $R(f^\\star) = \\frac{1}{n}\\sum_{i=1}^n(y_i-f^\\star(x_i))^2 = \\frac{1}{n}\\sum_{i=1}^n(y_i-(x_{i1}\\beta_1+...+x_{ip}\\beta_p))^2$.  \n",
    "Thus, $R_n(\\hat f) \\le R_n(f^\\star)$ because $\\hat f$ was fitted to the data by minimizing $\\ell$ at each $(x_i,y_i)$.  \n",
    "So $E(R_n(\\hat f)) \\le E(R_n(f^\\star) = R(f^\\star)$ since $\\beta$ is fixed.  \n",
    "__(4)__ We can deduce that $R(f^\\star) \\le R(\\hat f)$ by part (1).  \n",
    "So $E(R_n(\\hat f)) \\le R(f^\\star) \\le R(\\hat f) \\Rightarrow E(R_n(\\hat f)) \\le R(\\hat f)$.  \n",
    "Solution to ex 2.9 in ESL:  \n",
    "$R_{tr}(\\beta)$ corresponds to $R_n(\\beta)$ in (3) and (4).  \n",
    "We also know from (4) that $E(R_{tr}(\\beta)) \\le R(\\hat\\beta))$  \n",
    "So $E(R_{tr}(\\beta)) \\le (E(y - \\hat\\beta^Tx)^2) = E(R_{te}(\\beta))$ since $E(\\frac{1}{m}\\sum_{i=1}^m(\\tilde{y_i} - \\hat\\beta^T\\tilde{x_i})^2) = E(\\tilde{y_1}-\\hat\\beta^T\\tilde{x_1})^2)$.  \n",
    "__(5)__ We didn't use linearity directly; we only used the fact that the $\\hat f$ was fit to teh data by minimizing $\\ell$, so for a different $\\ell$, we should see the same results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1.4__ (5 pts) Ex. 3.5 in ESL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution:__  \n",
    "We insert zero as $\\bar x_j - \\bar x_j$ to obtain  \n",
    "$\\hat\\beta^{ridge} = \\operatorname{arg\\,min}_\\beta \\{\\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p \\bar x_j\\beta_j - \\sum_{j=1}^p(x_{ij}-\\bar x_j)\\beta_j)^2 + \\lambda \\sum_{j=1}^p\\beta_j^2 \\}$  \n",
    "Now if we define $\\beta_0^C = \\beta_0 + \\sum_{j=1}^p\\bar x_j\\beta_j$ and $\\beta_j^C = \\beta_i$ for $j=2,...,p$, we can rewrite as  \n",
    "$\\operatorname{arg\\,min}_{\\beta^C} \\{\\sum_{i=1}^N(y_i - \\beta_0^C - \\sum_{j=1}^p (x_{ij}-\\bar x_j)\\beta_j^C)^2 + \\lambda \\sum_{j=1}^p\\beta_j^C \\}$  \n",
    "Since we are centering the data, only the intercepts change (the $\\beta_0$). The slopes do not change ($\\beta_j$ for $j=2,...,p$).  \n",
    "For the lasso method:\n",
    "$\\hat\\beta^{lasso} = \\operatorname{arg\\,min}_\\beta \\{\\frac{1}{2}\\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p x_{ij}\\beta_j)^2 + \\lambda \\sum_{j=1}^p|\\beta_j| \\}$  \n",
    "It is clear that we can similarly insert zero as $\\bar x_j - \\bar x_j$ and define $\\beta_0^C$ and $\\beta_i^C$ the same as above to get a similar result (this time with absolute value in the last term and a $\\frac{1}{2}$ in front of the summand). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1.5__ (5 pts) Ex 3.9 in ESL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution:__\n",
    "Let $X_1 = QR$, where $Q = (q_1,...,q_q)$. Consider a predictor $x_k$ for $q < k \\le p$. The projection of $x_k$ on $span(X_1)$ is given by $P(x_k) = <x_k,q_1>q_1 +...+ <x_k,q_q>q_q$. The current fitted values is the projection of $y$ onto $span(X_1)$, ie, $\\hat y = P(y)$. Adding $x_k$ into the current set of predictors updates the fitted values to be $\\hat y = <y,q_k>q_k$. Thus, the current residual sum of squares is reduced by $<y,q_k>^2$. So we just need to find the predictor that maximizes $<y,q_k>^2$.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "You will be graded based on several criteria, and each is on a 5 point scale (5 is excellent - A - 1 is poor - C - 0 is not answered - D/F).  You should strive to 'impress us' if you want a 5.  This means excellent code, well explained conclusions, well annotated plots, correct answers, etc.\n",
    "\n",
    "We will be grading you on several criteria:\n",
    "\n",
    "- Conclusions: Conclusions should be consistent with the evidence provided, the conclusion should be well justified, the principles of machine learning that you have learned should be respected (such as overfitting and underfitting etc.)\n",
    "- Correctness of calculations: code should be correct and reflect the principles learned in this course, the logic should be sound, the methods should match the setting and context, you should try many applicable methods that you have learned as long as they apply. \n",
    "- Code, Figures, and Text: Code should be annotated and easy to follow, with docstrings on the functions; captions, titles,  for figures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2__ You should run the following code cells to import the code and reduce the variable set.  Address the questions after the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import linear_model, neighbors\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# dataset path\n",
    "data_dir = \"~/Dropbox/208/208-HW1-pamelot317\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.5</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.26</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.99630</td>\n",
       "      <td>3.25</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.5</td>\n",
       "      <td>0.99551</td>\n",
       "      <td>3.56</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.99600</td>\n",
       "      <td>3.28</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quality  density    pH  alcohol  time\n",
       "0     90.0  0.99780  3.51      9.4     5\n",
       "1     68.5  0.99620  3.26     10.0     4\n",
       "2    110.0  0.99630  3.25      9.2     5\n",
       "3     71.5  0.99551  3.56     10.8     5\n",
       "4    110.0  0.99600  3.28      9.8     6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.read_csv(data_dir+\"/hw1.csv\", delimiter=',')\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response variable is quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(sample_data.iloc[:,range(1,5)])\n",
    "y = np.array(sample_data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loo_risk(X,y,regmod):\n",
    "    \"\"\"\n",
    "    Construct the leave-one-out square error risk for a regression model\n",
    "    \n",
    "    Input: design matrix, X, response vector, y, a regression model, regmod\n",
    "    Output: scalar LOO risk\n",
    "    \"\"\"\n",
    "    loo = LeaveOneOut()\n",
    "    loo_losses = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        regmod.fit(X_train,y_train)\n",
    "        y_hat = regmod.predict(X_test)\n",
    "        loss = np.sum((y_hat - y_test)**2)\n",
    "        loo_losses.append(loss)\n",
    "    return np.mean(loo_losses)\n",
    "\n",
    "def emp_risk(X,y,regmod):\n",
    "    \"\"\"\n",
    "    Return the empirical risk for square error loss\n",
    "    \n",
    "    Input: design matrix, X, response vector, y, a regression model, regmod\n",
    "    Output: scalar empirical risk\n",
    "    \"\"\"\n",
    "    regmod.fit(X,y)\n",
    "    y_hat = regmod.predict(X)\n",
    "    return np.mean((y_hat - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2.1__ (5 pts) Compare the leave-one-out risk with the empirical risk for linear regression, on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO Risk: 243.53350804\n",
      "Emp Risk: 242.27402643\n"
     ]
    }
   ],
   "source": [
    "lin1 = linear_model.LinearRegression(fit_intercept=False)\n",
    "print('LOO Risk: '+ str(loo_risk(X,y,lin1)))\n",
    "print('Emp Risk: ' + str(emp_risk(X,y,lin1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the emperical risk is lower than the LOO risk, which is expected, but it is not a lot lower because n (the number of data points) is high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2.2__ (10 pts) Perform kNN regression and compare the leave-one-out risk with the empirical risk for k from 1 to 50.  Remark on the tradeoff between bias and variance for this dataset and compare against linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsRegressor(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAGSCAYAAABZp0PEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10436a6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOOs = []\n",
    "MSEs = []\n",
    "K=50\n",
    "Ks = range(1,K+1)\n",
    "for k in Ks:\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors=k)\n",
    "    LOOs.append(loo_risk(X,y,knn))\n",
    "    MSEs.append(emp_risk(X,y,knn))\n",
    "\n",
    "plt.plot(Ks,LOOs,'r',label=\"LOO risk\")\n",
    "plt.title(\"Risks for kNN Regression\")\n",
    "plt.plot(Ks,MSEs,'b',label=\"Emp risk\")\n",
    "plt.legend()\n",
    "_ = plt.xlabel('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233.81674477000831"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOOs[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the LOO risk stops improving after about k=13, but it doesn't appear that bias starts to really dominate until about k = 18, where we begin to see the LOO risk going back up. With low k, the variance is high, so we see the LOO risk is high (since leaving one out will drastically affect the outcome with small k). As we increase k, we see the LOO risk improve, until the bias starts to dominate. The LOO risk at k=13 is about 233.18, which is better than the LOO for linear regression that we saw above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2.3__ (10 pts) Implement forward stepwise regression (ESL section 3.3.2) for the linear model and compare the LOO risk for each stage.  Recall that at each step forward stepwise regression will select a new variable that most improves the empirical risk and include that in the model (starting with the intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n,p = X.shape\n",
    "Xsc = scale(X)\n",
    "ysc = scale(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subsetR(subset, Xsc, ysc, n):\n",
    "    \"\"\"Fits model and computes empirical risk for a given subset of features\n",
    "    input: a list of feature indices, scaled X and y matrices, number of rows of Xsc\n",
    "    output: the empirical for the linear regression model fitted to those features\"\"\"\n",
    "    lin1 = linear_model.LinearRegression(fit_intercept=False)\n",
    "    model = lin1.fit(Xsc[:,subset], ysc)\n",
    "    R = (((model.predict(Xsc[:,subset]) - ysc) ** 2).sum())/n\n",
    "    LOO = loo_risk(Xsc[:,subset],ysc,lin1)\n",
    "    return {'model': subset, 'R':R, 'LOO': LOO}\n",
    "\n",
    "def forward(pred, Xsc, ysc, n):\n",
    "    \"\"\"Peforms one step of the forward stepwise regression algorithm and returns an updated list of indices\n",
    "    of predictors\n",
    "    input: list of indices of predictor variables that have been accepted, scaled X and y matrices, number of rows\n",
    "    output: updated list of indices of predictor variables that have been accepted\"\"\"\n",
    "    rem_pred = [p for p in pd.DataFrame(Xsc).columns if p not in pred]\n",
    "    results = []\n",
    "    for p in rem_pred:\n",
    "        results.append(subsetR(pred+[p], Xsc, ysc, n))\n",
    "    models = pd.DataFrame(results)\n",
    "    best_model = models.loc[models['R'].argmin()]\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "final_models = pd.DataFrame(columns=['LOO', 'R', 'model'])\n",
    "\n",
    "for i in range(p):\n",
    "    final_models.loc[i] = forward(pred, Xsc, ysc, n)\n",
    "    pred = final_models.loc[i]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOO</th>\n",
       "      <th>R</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.853223</td>\n",
       "      <td>0.852019</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.809525</td>\n",
       "      <td>0.807354</td>\n",
       "      <td>[3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.802668</td>\n",
       "      <td>0.799527</td>\n",
       "      <td>[3, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803733</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>[3, 1, 2, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LOO         R         model\n",
       "0  0.853223  0.852019           [3]\n",
       "1  0.809525  0.807354        [3, 1]\n",
       "2  0.802668  0.799527     [3, 1, 2]\n",
       "3  0.803733  0.799518  [3, 1, 2, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best LOO risk occurs for a model with $X_2, X_3,$ and $X_4$, whereas the forward stepwise regression chose to include all of the $X$ variables when comparing the empirical risk. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
